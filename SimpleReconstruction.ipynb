{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd05ab81201b6ab877d8152339bbd004626ada1674ab0292653c2ad80d9dfac2197",
   "display_name": "Python 3.7.4 64-bit ('fedml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###IMPORTS \n",
    "import logging\n",
    "from collections import OrderedDict\n",
    "import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np\n",
    "\n",
    "import inversefed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EARLY STOPPING CLASS FOR FASTER RECONSTRUCTION\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    Code inspired by https://github.com/Bjarten/early-stopping-pytorch 26.03.2021\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=7, delta=0, metric='loss', subject_to='min', verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            metric (str): string of the metric we are looking at in our history\n",
    "            subject_to (str): Defines whether the metric is subject to minimazation or maximization; 'min' or 'max' (defaut or when misspelled: 'min')\n",
    "            verbose (bool): If True, logs a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.metric = metric\n",
    "        self.subject_to = subject_to\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.stop = False\n",
    "        self.improved = False\n",
    "        self.delta = delta\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.__dict__\n",
    "\n",
    "    def set_state(self, state_dict):\n",
    "        self.__dict__ = state_dict\n",
    "\n",
    "    def __call__(self, metric):\n",
    "        if self.subject_to == 'max':\n",
    "            score = -metric\n",
    "        else:\n",
    "            score = metric\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.improved = True\n",
    "            self.best_score = score\n",
    "        elif score >= self.best_score + self.delta:\n",
    "            self.improved = False\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                logging.info(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.stop = True\n",
    "        else:\n",
    "            self.improved = True\n",
    "            self.best_score = score\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MSE Metric Class\n",
    "class Metric:\n",
    "    def __init__(self):\n",
    "        self.metric_fn = None\n",
    "    def __call__(self, prediction, truth):\n",
    "        if self.metric_fn == None:\n",
    "            raise  NotImplementedError()\n",
    "        else:\n",
    "            return self.metric_fn(prediction, truth)\n",
    "            \n",
    "class MSE(Metric):\n",
    "    def __init__(self, reduce=True):\n",
    "        if reduce:\n",
    "            self.metric_fn = torch.nn.MSELoss(size_average=None, reduction='mean')\n",
    "        else:\n",
    "            self.metric_fn = self.mse\n",
    "        self.format = '.6f'\n",
    "        self.reduce = reduce\n",
    "        self.name = 'MSE'\n",
    "        self.target = 'features'\n",
    "\n",
    "    def mse(self, x, y):\n",
    "        if not self.reduce:\n",
    "            mse_fn = torch.nn.MSELoss(size_average=None, reduction='none')\n",
    "            value = mse_fn(x, y)\n",
    "            for _ in range(len(value.shape)-1):\n",
    "                value = value.mean(dim=-1)\n",
    "            return value\n",
    "        else:\n",
    "            print('You shouldn\\'t be here.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEFINE SOME BASIC FUNCTIONS\n",
    "def system_startup(args=None, defs=None):\n",
    "    \"\"\"Set Logging\"\"\"\n",
    "    rootLogger = logging.getLogger()\n",
    "    logFormatter = logging.Formatter('%(asctime)s:[%(levelname)s][%(filename)s][%(funcName)s] %(message)s')\n",
    "    consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "    consoleHandler.setFormatter(logFormatter)\n",
    "    rootLogger.addHandler(consoleHandler)\n",
    "    rootLogger.setLevel(logging.INFO)\n",
    "\n",
    "    \"\"\"Log useful system information.\"\"\"\n",
    "    # Choose GPU device and print status information:\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    #torch.multiprocessing.set_start_method('spawn')\n",
    "    device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    logging.info('Currently evaluating -------------------------------:')\n",
    "    logging.info(datetime.datetime.now().strftime(\"%A, %d. %B %Y %I:%M%p\"))\n",
    "    logging.info(f'CPUs: {torch.get_num_threads()}, GPUs: {torch.cuda.device_count()}.')\n",
    "    if args is not None:\n",
    "        logging.info(args)\n",
    "    if defs is not None:\n",
    "        logging.info(repr(defs))\n",
    "    if torch.cuda.is_available():\n",
    "        logging.info(f'GPU : {torch.cuda.get_device_name(device=device)}')\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    logging.info('Activating torch.autograd anomaly detection')\n",
    "    return device\n",
    "    \n",
    "def build_cifar10(batch_size = 64, datapath='./data/', train_transformations = transforms.ToTensor(), val_transformations = transforms.ToTensor()):\n",
    "    trn_set = torchvision.datasets.CIFAR10(root=datapath, train=True, download=True, transform=train_transformations)\n",
    "    tst_set = torchvision.datasets.CIFAR10(root=datapath, train=False, download=True, transform=val_transformations)\n",
    "    trn_loader = torch.utils.data.DataLoader(trn_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    tst_loader = torch.utils.data.DataLoader(tst_set, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    return trn_loader, tst_loader\n",
    "\n",
    "def get_gradient(model, input_data, gt_labels, loss_fn, train_mode, device):\n",
    "    print('Generatig gradient from victim data...')\n",
    "    if train_mode:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    model.zero_grad()\n",
    "    target_loss = loss_fn(model(input_data), gt_labels)\n",
    "    gradient = torch.autograd.grad(target_loss, model.parameters(), allow_unused=True)\n",
    "    #return gradient\n",
    "    gradient = [grad.detach() for grad in gradient if type(grad) == torch.Tensor]\n",
    "\n",
    "    return gradient\n",
    "\n",
    "def gradient_inversion(gradient, labels, model, data_shape, dm, ds, device):\n",
    "    print('Performing a Gradientinversion attack.')\n",
    "    #build inversefed library specific config for the reconstruction attack\n",
    "    c = dict(signed=True,\n",
    "              boxed=True,\n",
    "              cost_fn='sim',\n",
    "              indices='def',\n",
    "              weights='equal',\n",
    "              lr=0.1,\n",
    "              optim='adam',\n",
    "              restarts=1,\n",
    "              max_iterations=7000,\n",
    "              total_variation=1e-6,\n",
    "              init='randn',\n",
    "              filter='none',\n",
    "              lr_decay=True,\n",
    "              scoring_choice='loss',\n",
    "              loss_fn = torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean'), #(Loss fn the model was trianed with)\n",
    "              early_stopper = EarlyStopping(1000, 0, 'ReconstructionLoss', 'min', False)\n",
    "              )\n",
    "    rec_machine = inversefed.GradientReconstructor(model, (dm, ds), c, num_images=batch_size)\n",
    "    output, stats = rec_machine.reconstruct(gradient, labels, img_shape=data_shape)\n",
    "\n",
    "    return output, stats['opt']\n",
    "\n",
    "\n",
    "def match_reconstructions(images, reconstructions):\n",
    "    cost_matrix = get_similarity_cost_matrix(images, reconstructions)\n",
    "    rec_idx = linear_sum_assignment(cost_matrix, maximize=True)[1]\n",
    "    return reconstructions[rec_idx].detach().clone()\n",
    "\n",
    "\n",
    "def get_similarity_cost_matrix(images, reconstructions):\n",
    "    m = MSE(False)\n",
    "    cost_matrix = []\n",
    "    for img in images:\n",
    "        i, r = torch.broadcast_tensors(img, reconstructions)\n",
    "        current_metric = m(i, r)\n",
    "        cost_matrix.append(np.array(current_metric).astype(float))\n",
    "    return np.array(cost_matrix)\n",
    "\n",
    "def show_single_img(img):\n",
    "    plt.imshow(img.permute(1, 2, 0).cpu());\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Generatig gradient from victim data...\n",
      "Performing a Gradientinversion attack.\n"
     ]
    }
   ],
   "source": [
    "#Get Hardware\n",
    "device = system_startup()\n",
    "\n",
    "#Prep dataset\n",
    "trn_loader, tst_loader = build_cifar10(batch_size=16)\n",
    "for i, l in trn_loader:\n",
    "    images = i\n",
    "    labels = l\n",
    "    break\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "batch_size = images.shape[0]\n",
    "data_shape = (3,32,32)\n",
    "num_classes = 10\n",
    "\n",
    "cifar10_mean = [0.4914672374725342, 0.4822617471218109, 0.4467701315879822]\n",
    "cifar10_std = [0.24703224003314972, 0.24348513782024384, 0.26158785820007324]\n",
    "dm = torch.as_tensor(cifar10_mean)[:, None, None]\n",
    "ds = torch.as_tensor(cifar10_std)[:, None, None]\n",
    "\n",
    "#Get model and Loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n",
    "model = nn.Sequential(OrderedDict([\n",
    "            ('flatten', nn.Flatten()),\n",
    "            ('linear0', nn.Linear(np.prod(data_shape), 1024)),\n",
    "            ('relu0', nn.ReLU()),\n",
    "            ('linear1', nn.Linear(1024, 1024)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('linear2', nn.Linear(1024, num_classes))]))\n",
    "\n",
    "gradient = get_gradient(model, images, labels, loss_fn, True, device)\n",
    "output, best_loss = gradient_inversion(gradient, labels, model, data_shape, dm, ds, device)\n",
    "recs = match_reconstructions(images, output, MSE(False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(trn_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 32, 32]) 6\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}